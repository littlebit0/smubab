"""ìƒëª…ëŒ€í•™êµ ì‹ë‹¨í‘œ HTML êµ¬ì¡° ë¶„ì„"""
import requests
from bs4 import BeautifulSoup

def analyze_seoul():
    print("\n" + "="*80)
    print("ğŸ“ ì„œìš¸ìº í¼ìŠ¤")
    print("="*80)
    
    url = 'https://www.smu.ac.kr/kor/life/restaurantView.do'
    response = requests.get(url, timeout=15)
    soup = BeautifulSoup(response.text, 'html.parser')
    
    tables = soup.find_all('table')
    print(f"\nì´ {len(tables)}ê°œ í…Œì´ë¸”")
    
    for i, table in enumerate(tables, 1):
        print(f"\n[í…Œì´ë¸” {i}]")
        rows = table.find_all('tr')
        print(f"  í–‰ ìˆ˜: {len(rows)}")
        
        for j, row in enumerate(rows[:5], 1):
            cells = row.find_all(['td', 'th'])
            texts = [c.get_text(strip=True)[:25] for c in cells[:4]]
            if any(texts):
                print(f"  í–‰{j}: {texts}")

def analyze_cheonan():
    urls = {
        "ì²œì•ˆ_êµì§ì›": "https://www.smu.ac.kr/kor/life/restaurantView3.do",
        "ì²œì•ˆ_í•™ìƒ": "https://www.smu.ac.kr/kor/life/restaurantView4.do"
    }
    
    for name, url in urls.items():
        print("\n" + "="*80)
        print(f"ğŸ“ {name}")
        print("="*80)
        
        response = requests.get(url, timeout=15)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # í…Œì´ë¸”ì˜ ëª¨ë“  í–‰ í™•ì¸
        table = soup.find('table')
        if table:
            rows = table.find_all('tr')
            print(f"\ní…Œì´ë¸” í–‰ ìˆ˜: {len(rows)}")
            
            for i, row in enumerate(rows[:10], 1):
                cells = row.find_all(['td', 'th'])
                texts = [c.get_text(strip=True)[:30] for c in cells]
                if any(texts):
                    print(f"  í–‰{i}: {texts}")
        
        # ì´ë¯¸ì§€ì™€ ë§í¬ í™•ì¸
        print("\nğŸ–¼ï¸ ì´ë¯¸ì§€ ë§í¬:")
        imgs = soup.find_all('img', src=True)
        for img in imgs[:3]:
            print(f"  {img.get('src')[:70]}")
        
        print("\nğŸ“ a íƒœê·¸:")
        links = soup.find_all('a', href=True)[:10]
        for link in links:
            href = link.get('href')
            text = link.get_text(strip=True)[:30]
            if text:
                print(f"  [{text}] -> {href[:60]}")

if __name__ == "__main__":
    try:
        analyze_seoul()
        analyze_cheonan()
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()
